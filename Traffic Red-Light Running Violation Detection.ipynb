{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d361def3",
   "metadata": {},
   "source": [
    "# Traffic Red-Light Running Violation Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6385ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12250cc",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150c1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "COLORS = {\n",
    "    \"GREEN\" :(0, 255, 0),\n",
    "    \"YELLOW\" : (0, 255, 255),\n",
    "    \"RED\" : (0, 0, 255),\n",
    "    \"BLUE\": (255, 0, 0)\n",
    "}\n",
    "\n",
    "TRAFFICLIGHTS = {\n",
    "    \"RED\": 13,\n",
    "    \"YELLOW\": 16,\n",
    "    \"GREEN\": 19,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fb637",
   "metadata": {},
   "source": [
    "## Cross Line Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd33d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_draw_cross_line(image, color=\"GREEN\"):\n",
    "    # set color\n",
    "    color = COLORS.get(color.upper(), (255, 0, 0))\n",
    "\n",
    "    # Convert image to HSV colorspace\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define range of yellow color in HSV\n",
    "    lower_yellow = np.array([20, 100, 100])\n",
    "    upper_yellow = np.array([30, 255, 255])\n",
    "\n",
    "    # Threshold the HSV image to get only yellow colors\n",
    "    yellow_mask = cv2.inRange(hsv_image, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    color_isolated = cv2.bitwise_and(image, image, mask=yellow_mask)\n",
    "\n",
    "    # Convert to Grayscale\n",
    "    gray = cv2.cvtColor(color_isolated, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define a kernel size and apply Gaussian smoothing\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Define our parameters for Canny and apply it to detect edges\n",
    "    edges = cv2.Canny(blurred, 50, 120)\n",
    "\n",
    "    # Create a masked edges image using cv2.fillPoly()\n",
    "    mask = np.zeros_like(edges)\n",
    "    ignore_mask_color = 255\n",
    "    # Define a four-sided polygon to mask\n",
    "    imshape = image.shape\n",
    "    vertices = np.array([\n",
    "        [\n",
    "            (0, int(imshape[0] * 0.9)),  # bottom left\n",
    "            (0, int(imshape[0] * 0.6)),  # top left \n",
    "            (imshape[1], int(imshape[0] * 0.6)),  # top right\n",
    "            (imshape[1], int(imshape[0] * 0.9))  # bottom right\n",
    "        ]\n",
    "    ], dtype=np.int32)\n",
    "\n",
    "    # Apply the polygon as a mask to the edges image\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "\n",
    "    # # start test\n",
    "    # # Draw the polygon on the image\n",
    "    # image_with_polygon = image.copy()\n",
    "    # cv2.polylines(image_with_polygon, [vertices], isClosed=True, color=(255, 255, 255), thickness=2)\n",
    "    # return image_with_polygon\n",
    "    # # end test\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    lines = cv2.HoughLinesP(masked_edges, rho=1, theta=np.pi / 180, threshold=30, minLineLength=15, maxLineGap=1)\n",
    "\n",
    "    cross_line = None\n",
    "    if lines is not None:\n",
    "        # Find the line with the maximum y2 value to get the lowest line in the image\n",
    "        line = max(lines, key=lambda line: line[0][3])\n",
    "\n",
    "        # Draw the line across the bottom of the detected speed bump\n",
    "        x, y, w, h = cross_line = line[0]\n",
    "        cv2.line(image, (0, h), (imshape[1], h), color, 2)  # color line with thickness 2\n",
    "        cv2.putText(image, \"Cross Line\", (20, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "    # # start debug\n",
    "    # # Visualize the intermediate steps for debugging\n",
    "    # cv2.imshow(\"Yellow Mask\", cv2.resize(yellow_mask, (0, 0), fx=0.5, fy=0.5))\n",
    "    # cv2.imshow(\"Color Isolated\", cv2.resize(color_isolated, (0, 0), fx=0.5, fy=0.5))\n",
    "    # cv2.imshow(\"Edges\", cv2.resize(edges, (0, 0), fx=0.5, fy=0.5))\n",
    "    # cv2.imshow(\"Masked Edges\", cv2.resize(masked_edges, (0, 0), fx=0.5, fy=0.5))\n",
    "    # # end of debug\n",
    "\n",
    "\n",
    "    return image, cross_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e67e71",
   "metadata": {},
   "source": [
    "## License Plate Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfffce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_plate_with_error_margin(frame, plate_location, error_margin_px):\n",
    "    x, y, w, h = plate_location\n",
    "\n",
    "    # Get the frame dimensions\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # Calculate new coordinates with the error margin\n",
    "    x_start = max(x - error_margin_px, 0)\n",
    "    y_start = max(y - error_margin_px, 0)\n",
    "    x_end = min(x + w + error_margin_px, frame_width)\n",
    "    y_end = min(y + h + error_margin_px, frame_height)\n",
    "\n",
    "    # Crop the frame using the new coordinates\n",
    "    cropped_frame = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    return cropped_frame\n",
    "\n",
    "def plate_detector(frame, car):\n",
    "    # Create an array of zeros with the same shape as the frame\n",
    "    mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "\n",
    "    # Extract the car coordinates\n",
    "    x, y, w, h = car\n",
    "\n",
    "    # Set the car region to the original frame values\n",
    "    mask[y:y+h, x:x+w] = frame[y:y+h, x:x+w]\n",
    "\n",
    "    gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    # apply a blur to make contours more thick\n",
    "    filtered = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # perform canny edge detection\n",
    "    edged = cv2.Canny(filtered, 10, 100) \n",
    "    # find coutours on edge detected image\n",
    "    contours = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contours_redefined = imutils.grab_contours(contours)\n",
    "\n",
    "    # sort contours by their area size so we search in biggest shapres first\n",
    "    contours_redefined = sorted(contours_redefined, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    # for contour in contours_redefined:\n",
    "    #     contour_approx = cv2.approxPolyDP(contour, 10, True)\n",
    "    #     if len(contour_approx) == 4:\n",
    "    #         plate_location = contour_approx\n",
    "    #         break\n",
    "\n",
    "    # frame = cv2.drawContours(frame, [plate_location], -1, (0, 255, 0), 2)\n",
    "\n",
    "    plate = False\n",
    "    plate_location = None\n",
    "    # loop over our contours\n",
    "    for c in contours_redefined:\n",
    "        # approximate the contour\n",
    "        perimeter = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 20, True)\n",
    "        # if our approximated contour has four points\n",
    "        # and have big enough area, then\n",
    "        # we can assume that we have found license plate\n",
    "        if len(approx) == 4 and cv2.contourArea(c) > 1000:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            if 2.5 < w / h < 4.1:\n",
    "                plate = True\n",
    "                plate_location = x, y, w, h\n",
    "                # # comment it for test -> start\n",
    "                # cv2.drawContours(frame, c, -1, (0, 255, 0), 1)\n",
    "                # cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "                # # comment it for test -> end\n",
    "                break\n",
    "    \n",
    "    # if we still could'nt find the plate we keep looking with some diffrent rules\n",
    "    if not plate:\n",
    "        for c in contours_redefined:\n",
    "            perimeter = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 20, True)\n",
    "            # if our approximated contour has more than four points\n",
    "            # then we check for its radio and if its between 2.5 and 4.5\n",
    "            # we could use that as plate (but its not accurate and needs work)\n",
    "            if len(approx) >= 4:\n",
    "                x, y, w, h = cv2.boundingRect(c)\n",
    "                if 2.5 < w / h < 4.5 and 10000 <= (w * h):\n",
    "                    # b, g, r = cv2.split(img[y:y + h, x - 20:x])\n",
    "                    plate = True\n",
    "                    plate_location = x, y, w, h\n",
    "                    # # comment it for test -> start\n",
    "                    # cv2.drawContours(frame, c, -1, (0, 255, 0), 1)\n",
    "                    # cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "                    # # comment it for test -> end\n",
    "                    break\n",
    "\n",
    "    # # show the plate image\n",
    "    # cv2.imshow('image', frame)\n",
    "    # cv2.imshow('edged', edged)\n",
    "\n",
    "    # if we found any plates then crop and save that part\n",
    "    cropped = None\n",
    "    if plate:\n",
    "        x, y, w, h = plate_location\n",
    "        error_margin_px = 0\n",
    "        cropped = crop_plate_with_error_margin(frame, plate_location, error_margin_px)\n",
    "        # cropped = frame[y+error_margin_px:y+h-error_margin_px, x+error_margin_px:x+w-error_margin_px]\n",
    "        # cv2.imshow('plate', cropped)\n",
    "        # cv2.imwrite('plate.jpg', cropped)\n",
    "\n",
    "    return frame, cropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2674e",
   "metadata": {},
   "source": [
    "### test for license plate detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866225f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start test for plate detector sections\n",
    "cars = [(1351, 988, 417, 72), (1100, 777, 540, 255), (1181, 653, 299, 132), (995, 637, 228, 199), (833, 625, 182, 276), (796, 596, 70, 66)]\n",
    "frame = cv2.imread('tests/frame2.jpg', -1)\n",
    "frame, cropped = plate_detector(frame, cars[1])\n",
    "# frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "# cv2.imshow(\"remove\", frame)\n",
    "cv2.imshow(\"plate\", cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# end test for plate detector sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde8c8c",
   "metadata": {},
   "source": [
    "## plate image enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08350cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges_and_enhance_image(image, resize_factor=2, low_threshold=50, high_threshold=150, mean_filter_size=5):\n",
    "    # Step 1: Edge Detection with Canny\n",
    "    edges = cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "    # Step 2: Resize the Edge Image to a Larger Size\n",
    "    original_size = (image.shape[1], image.shape[0])\n",
    "    new_size = (int(original_size[0] * resize_factor), int(original_size[1] * resize_factor))\n",
    "    resized_edges = cv2.resize(edges, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Step 3: Enhance the Image in Color\n",
    "    # Resize the original color image\n",
    "    resized_image = cv2.resize(image, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Convert the resized color image to YUV color space\n",
    "    yuv_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2YUV)\n",
    "    \n",
    "    # Apply histogram equalization to the Y channel\n",
    "    yuv_image[:, :, 0] = cv2.equalizeHist(yuv_image[:, :, 0])\n",
    "    \n",
    "    # Convert back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(yuv_image, cv2.COLOR_YUV2BGR)\n",
    "    \n",
    "    # Apply sharpening to the enhanced color image\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    sharpened_image = cv2.filter2D(enhanced_image, -1, kernel)\n",
    "\n",
    "    # Apply mean filter to the sharpened image\n",
    "    mean_filtered_image = cv2.blur(sharpened_image, (mean_filter_size, mean_filter_size))\n",
    "\n",
    "    # # Step 4: Convert blue pixels to white in HSV color space\n",
    "    # # Convert the mean filtered image to HSV color space\n",
    "    # # (just for remove left side of plate)\n",
    "    # hsv_image = cv2.cvtColor(mean_filtered_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # # Define range of blue color in HSV\n",
    "    # lower_blue = np.array([100, 150, 0])\n",
    "    # upper_blue = np.array([140, 255, 255])\n",
    "\n",
    "    # # Create a mask for blue color\n",
    "    # blue_mask = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "\n",
    "    # # Convert blue pixels to white\n",
    "    # mean_filtered_image[blue_mask > 0] = [255, 255, 255]\n",
    "\n",
    "    return resized_edges, mean_filtered_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e464af6",
   "metadata": {},
   "source": [
    "### test for edge detection and image enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b91c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start for test\n",
    "# Perform edge detection and enhancement\n",
    "plate = cv2.imread(\"tests/cropped.jpg\", -1)\n",
    "edges, enhanced_image = detect_edges_and_enhance_image(plate, resize_factor=2, low_threshold=50, high_threshold=150, mean_filter_size=5)\n",
    "\n",
    "# Display the results\n",
    "cv2.imshow(\"Edges\", edges)\n",
    "cv2.imshow(\"Enhanced Image\", enhanced_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# end for test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406c77a",
   "metadata": {},
   "source": [
    "## plate recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81194b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plate_recognizer(plate_image):\n",
    "    IMAGE_WIDTH = 70\n",
    "    IMAGE_HEIGHT = 70\n",
    "    # for test\n",
    "    SHOW_STEPS = False\n",
    "\n",
    "    # load trained data from images and classifications\n",
    "    npa_classifications = np.loadtxt(\"classifications.txt\", np.float32)\n",
    "    npa_flattenedImages = np.loadtxt(\"flattened_images.txt\", np.float32)\n",
    "    # create KNN object\n",
    "    k_nearest = cv2.ml.KNearest_create()\n",
    "    # train KNN object with training data\n",
    "    k_nearest.train(npa_flattenedImages, cv2.ml.ROW_SAMPLE, npa_classifications)\n",
    "\n",
    "    # load plate image\n",
    "    img = plate_image\n",
    "    # apply a blur to make edges thick\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # apply a threshhold to make image black & white\n",
    "    gray = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # find contours on the black & white image\n",
    "    contours, hir = cv2.findContours(gray.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # validating characters\n",
    "    # Note: Since in Farsi characters we have characters with more than one characters (like chars with dots)\n",
    "    # so we need to validate that they are characters or not \n",
    "    valid_contours = []\n",
    "    for c in contours:\n",
    "        [_, _, w, h] = cv2.boundingRect(c)\n",
    "        if w * h >= 400:\n",
    "            valid_contours.append(c)\n",
    "\n",
    "    # cv2.drawContours(img, valid_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # sort characters by their bouding size\n",
    "    valid_contours = sorted(valid_contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "    # store the plate number\n",
    "    plate_number = []\n",
    "\n",
    "    # loop through the valid contours (characters)\n",
    "    for c in valid_contours:\n",
    "        # store boundings\n",
    "        [x, y, w, h] = cv2.boundingRect(c)\n",
    "        # check for dots or etc\n",
    "        # Method: check anything in Y axis if their boundings are in X axis\n",
    "        # Explain: cause dots in Arabic/Farsi characters are above and below the character itself\n",
    "        for c2 in contours:\n",
    "            [x2, y2, w2, h2] = cv2.boundingRect(c2)\n",
    "            if x2 >= x and x2 <= x + w:\n",
    "                if y2 < y:\n",
    "                    h += abs(y - y2)\n",
    "                    y = y2\n",
    "                if y2 > y + h:\n",
    "                    h += abs(y2 - (y + h))\n",
    "\n",
    "        # draw rectangle around the characters\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "\n",
    "        # crop the character from grayscale image\n",
    "        char_image = gray[y:y + h, x:x + w]\n",
    "        # resize character to training size so we could compare those\n",
    "        char_image = cv2.resize(char_image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        # reshape resized character to numpy array\n",
    "        npa = np.float32(char_image.reshape((1, IMAGE_WIDTH * IMAGE_HEIGHT)))\n",
    "\n",
    "        # store results of compare between character and training data and find nearest possible example\n",
    "        retval, npaResults, neigh_resp, dists = k_nearest.findNearest(npa, k=1)\n",
    "\n",
    "        # convert the result found in classifications to normal character and print it on output\n",
    "        # print(chr(int(npaResults[0][0])), end='')\n",
    "        plate_number.append(chr(int(npaResults[0][0])))\n",
    "\n",
    "        if SHOW_STEPS:\n",
    "            cv2.imshow('test', char_image)\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "    if SHOW_STEPS:\n",
    "        cv2.imshow('test', gray)\n",
    "        cv2.imshow('test2', img)\n",
    "        cv2.waitKeyEx(0)\n",
    "\n",
    "    # use for test\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    # for removing letter from start of plate\n",
    "    while True:\n",
    "        try:\n",
    "            if plate_number[0].isdigit():\n",
    "                break\n",
    "            else:\n",
    "                plate_number.pop(0)\n",
    "        except IndexError:\n",
    "            break\n",
    "\n",
    "    # for removing letter from end of plate\n",
    "    while True:\n",
    "        try:\n",
    "            if plate_number[-1].isdigit():\n",
    "                break\n",
    "            else:\n",
    "                plate_number.pop(-1)\n",
    "        except IndexError:\n",
    "            break\n",
    "    \n",
    "    valid = False\n",
    "    # check if plate is valid\n",
    "    plate_number = \"\".join(plate_number)\n",
    "    if  5 <= len(plate_number) <= 8:\n",
    "        valid = True\n",
    "    \n",
    "    return valid, plate_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520d49a",
   "metadata": {},
   "source": [
    "### test for plate recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a60bde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid plate: True\n",
      "License plate: ۸۴و۷۶۱۴۲\n"
     ]
    }
   ],
   "source": [
    "# start for test\n",
    "enhanced_image = cv2.imread(\"tests/enhanced_image.jpg\", -1)\n",
    "valid, plate_number = plate_recognizer(enhanced_image)\n",
    "print(f'Valid plate: {valid}')\n",
    "print(f'License plate: {plate_number}')\n",
    "# end for test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a55d5",
   "metadata": {},
   "source": [
    "## DB section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3564caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to db\n",
    "conn = sqlite3.connect('database.db')\n",
    "\n",
    "# create cursor for execute cmd\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# create table to store license plates of offending cars\n",
    "cursor.execute(\"CREATE TABLE IF NOT EXISTS Plates (id INTEGER PRIMARY KEY, plate TEXT, time INTEGER)\")\n",
    "\n",
    "# commit changes\n",
    "conn.commit()\n",
    "\n",
    "# close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc1ca6",
   "metadata": {},
   "source": [
    "## Insert plate into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ebdf9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_panalty(plate_text, crime_time):\n",
    "    # connect to db\n",
    "    conn = sqlite3.connect('database.db')\n",
    "\n",
    "    # create cursor for execute cmd\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # get the last time of penalty for this plate\n",
    "    cursor.execute(\"SELECT time FROM Plates WHERE plate=? ORDER BY time DESC LIMIT 1\", (plate_text,))\n",
    " \n",
    "    last_time_row = cursor.fetchone()\n",
    "    \n",
    "    if last_time_row is not None:\n",
    "        last_time = last_time_row[0]\n",
    "        time_difference = crime_time - last_time\n",
    "        if time_difference >= 60: # Penalty for every 60 seconds\n",
    "            # insert new data\n",
    "            cursor.execute(\"INSERT INTO Plates (plate, time) VALUES (?, ?)\", (plate_text, crime_time))\n",
    "            print(f\"Penalty for {plate_text}\")\n",
    "    else:\n",
    "        # insert new data\n",
    "        cursor.execute(\"INSERT INTO Plates (plate, time) VALUES (?, ?)\", (plate_text, crime_time))\n",
    "        print(f\"Penalty for {plate_text}\")\n",
    "\n",
    "    # commit changes\n",
    "    conn.commit()\n",
    "\n",
    "    # close the connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642559d5",
   "metadata": {},
   "source": [
    "## Main Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video time: 1s\n",
      "Lights color: red\n",
      "Penalty for ۸۴و۷۶۱۶۲\n",
      "Video time: 2s\n",
      "Lights color: red\n",
      "Video time: 3s\n",
      "Lights color: red\n",
      "Video time: 4s\n",
      "Lights color: red\n",
      "Video time: 5s\n",
      "Lights color: red\n",
      "Video time: 6s\n",
      "Lights color: red\n",
      "Video time: 7s\n",
      "Lights color: red\n",
      "Video time: 8s\n",
      "Lights color: red\n",
      "Video time: 9s\n",
      "Lights color: red\n",
      "Video time: 10s\n",
      "Lights color: red\n",
      "Video time: 11s\n",
      "Lights color: red\n",
      "Video time: 12s\n",
      "Lights color: red\n",
      "Video time: 13s\n",
      "Lights color: red\n",
      "Video time: 14s\n",
      "Lights color: red\n",
      "Video time: 15s\n",
      "Lights color: red\n",
      "Video time: 16s\n",
      "Lights color: red\n",
      "Video time: 17s\n",
      "Lights color: yellow\n",
      "Video time: 18s\n",
      "Lights color: yellow\n",
      "Video time: 19s\n",
      "Lights color: yellow\n",
      "Video time: 20s\n",
      "Lights color: green\n",
      "Video time: 21s\n",
      "Lights color: green\n",
      "Video time: 22s\n",
      "Lights color: green\n",
      "Video time: 23s\n",
      "Lights color: green\n"
     ]
    }
   ],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(\"DIP_Proj_short.mp4\")\n",
    "\n",
    "# Get the original FPS of the video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_delay = int(1000 / fps)  # Calculate the delay between frames in milliseconds\n",
    "\n",
    "# set config for save video\n",
    "output_video = 'DIP_output_video.mp4'\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "# Initialize background subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=100, detectShadows=False)\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False) # better result\n",
    "\n",
    "# set detect car color\n",
    "blue_color = COLORS.get(\"blue\".upper())\n",
    "red_color = COLORS.get(\"red\".upper())\n",
    "yellow_color = COLORS.get(\"yellow\".upper())\n",
    "green_color = COLORS.get(\"green\".upper())\n",
    "\n",
    "frame_count = 0\n",
    "seconds = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()  # Start time for frame processing\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Specifying the color of traffic lights\n",
    "    if seconds >= TRAFFICLIGHTS[\"GREEN\"]:\n",
    "        lights_color = \"green\"\n",
    "    elif seconds >= TRAFFICLIGHTS[\"YELLOW\"]:\n",
    "        lights_color = \"yellow\"\n",
    "    else:\n",
    "        lights_color = \"red\"\n",
    "\n",
    "    # Write Light Color status on corner of frame\n",
    "    lights_color_rgb = COLORS.get(lights_color.upper())\n",
    "    cv2.putText(frame, f\"Lights Color: {lights_color.capitalize()}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, lights_color_rgb, 5)\n",
    "    \n",
    "\n",
    "    # find out seconds of video based reading frame\n",
    "    if frame_count % fps == 0:\n",
    "        seconds += 1\n",
    "        print(f\"Video time: {seconds}s\")\n",
    "        print(f\"Lights color: {lights_color}\")\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Resize frame to half of its original size to speed up processing\n",
    "    # frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    # copy frame\n",
    "    org_frame = frame.copy()\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Apply some morphological operations to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Detect and draw the yellow speed bump line\n",
    "    frame, cross_line = detect_draw_cross_line(frame, lights_color)\n",
    "    if cross_line is not None:\n",
    "        _, _, _, h_cross = cross_line\n",
    "    else:\n",
    "        h_cross = -1\n",
    "\n",
    "    # List to store car detections for the current frame\n",
    "    car_detections = []\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        # Filter out small contours\n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "        # if cv2.contourArea(contour) < 5000: better result\n",
    "            continue\n",
    "\n",
    "        # Get bounding box for each contour\n",
    "        car_color = blue_color\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        if (y+h) >= h_cross and lights_color == \"red\":\n",
    "            car_color = red_color\n",
    "        elif (y+h) >= h_cross and lights_color == \"yellow\":\n",
    "            car_color = yellow_color\n",
    "        elif (y+h) >= h_cross and lights_color == \"green\":\n",
    "            car_color = green_color\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), car_color, 2)\n",
    "        cv2.putText(frame, \"Car\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, car_color, 2)\n",
    "        \n",
    "        # Add the detection to the list\n",
    "        car_detections.append((x, y, w, h))\n",
    "\n",
    "    # detect crime car\n",
    "    for car in car_detections:\n",
    "        x, y, w, h = car\n",
    "        if (y+h) >= h_cross:\n",
    "            _frame, cropped = plate_detector(org_frame, car)\n",
    "            if type(cropped) != np.ndarray:\n",
    "                continue\n",
    "            edges, enhanced_image = detect_edges_and_enhance_image(plate, resize_factor=2, low_threshold=50, high_threshold=150, mean_filter_size=5)\n",
    "            valid, plate_number = plate_recognizer(enhanced_image)\n",
    "            if valid:\n",
    "                insert_panalty(plate_number, seconds)\n",
    "\n",
    "\n",
    "    # Write the modified frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the frame\n",
    "    frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # # Print or save car detections for the current frame\n",
    "    # print(f\"Frame {int(cap.get(cv2.CAP_PROP_POS_FRAMES))} detections: {car_detections}\")\n",
    "\n",
    "    # Calculate the time spent processing the frame\n",
    "    elapsed_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Calculate the wait time to match the original FPS\n",
    "    wait_time = max(int(frame_delay - elapsed_time), 1)\n",
    "\n",
    "    if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332e53f",
   "metadata": {},
   "source": [
    "## Clear all rows the plate table of DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24985018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to db\n",
    "conn = sqlite3.connect('database.db')\n",
    "\n",
    "# create cursor for execute cmd\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# delete all rows from table\n",
    "cursor.execute(\"DELETE FROM plates\")\n",
    "\n",
    "# commit changes\n",
    "conn.commit()\n",
    "\n",
    "# close the connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
